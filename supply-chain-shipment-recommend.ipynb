{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\npd.set_option('max_columns', None)\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\n\nimport tensorflow as tf\n\nfrom sklearn.metrics import confusion_matrix, classification_report","metadata":{"execution":{"iopub.status.busy":"2022-01-04T12:40:28.900990Z","iopub.execute_input":"2022-01-04T12:40:28.901407Z","iopub.status.idle":"2022-01-04T12:40:35.942429Z","shell.execute_reply.started":"2022-01-04T12:40:28.901322Z","shell.execute_reply":"2022-01-04T12:40:35.941319Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv('../input/supply-chain-analysis-and-modeling/SCMS_Delivery_History_Dataset.csv')","metadata":{"execution":{"iopub.status.busy":"2022-01-04T12:40:35.946796Z","iopub.execute_input":"2022-01-04T12:40:35.947122Z","iopub.status.idle":"2022-01-04T12:40:36.126351Z","shell.execute_reply.started":"2022-01-04T12:40:35.947095Z","shell.execute_reply":"2022-01-04T12:40:36.125281Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"data","metadata":{"execution":{"iopub.status.busy":"2022-01-04T12:40:36.127438Z","iopub.execute_input":"2022-01-04T12:40:36.127718Z","iopub.status.idle":"2022-01-04T12:40:36.198921Z","shell.execute_reply.started":"2022-01-04T12:40:36.127682Z","shell.execute_reply":"2022-01-04T12:40:36.198156Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"data.info()","metadata":{"execution":{"iopub.status.busy":"2022-01-04T12:40:36.199908Z","iopub.execute_input":"2022-01-04T12:40:36.200306Z","iopub.status.idle":"2022-01-04T12:40:36.247963Z","shell.execute_reply.started":"2022-01-04T12:40:36.200277Z","shell.execute_reply":"2022-01-04T12:40:36.247062Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"def preprocess_inputs(df, label_mapping):\n    df = df.copy()\n    \n    # Drop ID column\n    df = df.drop('ID', axis=1)\n    \n    # Drop missing target rows\n    missing_target_rows = df[df['Shipment Mode'].isna()].index\n    df = df.drop(missing_target_rows, axis=0).reset_index(drop=True)\n    \n    # Fill missing values\n    df['Dosage'] = df['Dosage'].fillna(df['Dosage'].mode()[0])\n    df['Line Item Insurance (USD)'] = df['Line Item Insurance (USD)'].fillna(df['Line Item Insurance (USD)'].mean())\n    \n    # Drop date columns with too many missing values\n    df = df.drop(['PQ First Sent to Client Date', 'PO Sent to Vendor Date'], axis=1)\n    \n    # Extract date features\n    for column in ['Scheduled Delivery Date', 'Delivered to Client Date', 'Delivery Recorded Date']:\n        df[column] = pd.to_datetime(df[column])\n        df[column + ' Year'] = df[column].apply(lambda x: x.year)\n        df[column + ' Month'] = df[column].apply(lambda x: x.month)\n        df[column + ' Day'] = df[column].apply(lambda x: x.day)\n        df = df.drop(column, axis=1)\n    \n    # Drop numeric columns with too many missing values\n    df = df.drop(['Weight (Kilograms)', 'Freight Cost (USD)'], axis=1)\n    \n    # Drop high-cardinality columns\n    df = df.drop(['PQ #', 'PO / SO #', 'ASN/DN #'], axis=1)\n    \n    # Binary encoding\n    df['Fulfill Via'] = df['Fulfill Via'].replace({'Direct Drop': 0, 'From RDC': 1})\n    df['First Line Designation'] = df['First Line Designation'].replace({'No': 0, 'Yes': 1})\n    \n    # One-hot encoding\n    for column in df.select_dtypes('object').columns.drop('Shipment Mode'):\n        dummies = pd.get_dummies(df[column], prefix=column)\n        df = pd.concat([df, dummies], axis=1)\n        df = df.drop(column, axis=1)\n    \n    # Split df into X and y\n    y = df['Shipment Mode']\n    X = df.drop('Shipment Mode', axis=1)\n    \n    # Encode the labels\n    y = y.replace(label_mapping)\n    \n    # Train-test split\n    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, shuffle=True, random_state=1)\n    \n    # Scale X\n    scaler = StandardScaler()\n    scaler.fit(X_train)\n    X_train = pd.DataFrame(scaler.transform(X_train), index=X_train.index, columns=X_train.columns)\n    X_test = pd.DataFrame(scaler.transform(X_test), index=X_test.index, columns=X_test.columns)\n    \n    return X_train, X_test, y_train, y_test","metadata":{"execution":{"iopub.status.busy":"2022-01-04T12:40:36.250952Z","iopub.execute_input":"2022-01-04T12:40:36.251326Z","iopub.status.idle":"2022-01-04T12:40:36.267831Z","shell.execute_reply.started":"2022-01-04T12:40:36.251292Z","shell.execute_reply":"2022-01-04T12:40:36.266328Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"LABEL_MAPPING = {\n    'Air': 0,\n    'Truck': 1,\n    'Air Charter': 2,\n    'Ocean': 3\n}\n\nX_train, X_test, y_train, y_test = preprocess_inputs(data, label_mapping=LABEL_MAPPING)","metadata":{"execution":{"iopub.status.busy":"2022-01-04T12:40:36.269723Z","iopub.execute_input":"2022-01-04T12:40:36.270292Z","iopub.status.idle":"2022-01-04T12:40:37.907373Z","shell.execute_reply.started":"2022-01-04T12:40:36.270246Z","shell.execute_reply":"2022-01-04T12:40:37.906306Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"X_train","metadata":{"execution":{"iopub.status.busy":"2022-01-04T12:40:37.908841Z","iopub.execute_input":"2022-01-04T12:40:37.909296Z","iopub.status.idle":"2022-01-04T12:40:38.768307Z","shell.execute_reply.started":"2022-01-04T12:40:37.909254Z","shell.execute_reply":"2022-01-04T12:40:38.767451Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"y_train.value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-01-04T12:40:38.769347Z","iopub.execute_input":"2022-01-04T12:40:38.769743Z","iopub.status.idle":"2022-01-04T12:40:38.776209Z","shell.execute_reply.started":"2022-01-04T12:40:38.769714Z","shell.execute_reply":"2022-01-04T12:40:38.775150Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"X_train.shape","metadata":{"execution":{"iopub.status.busy":"2022-01-04T12:40:38.777694Z","iopub.execute_input":"2022-01-04T12:40:38.778256Z","iopub.status.idle":"2022-01-04T12:40:38.786815Z","shell.execute_reply.started":"2022-01-04T12:40:38.778223Z","shell.execute_reply":"2022-01-04T12:40:38.786087Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"inputs = tf.keras.Input(shape=(771,))\nx = tf.keras.layers.Dense(128, activation='relu')(inputs)\nx = tf.keras.layers.Dense(128, activation='relu')(x)\noutputs = tf.keras.layers.Dense(4, activation='softmax')(x)\n\nmodel = tf.keras.Model(inputs=inputs, outputs=outputs)\n\nmodel.compile(\n    optimizer='adam',\n    loss='sparse_categorical_crossentropy',\n    metrics=['accuracy']\n)\n\nhistory = model.fit(\n    X_train,\n    y_train,\n    validation_split=0.2,\n    batch_size=32,\n    epochs=100,\n    callbacks=[\n        tf.keras.callbacks.EarlyStopping(\n            monitor='val_loss',\n            patience=3,\n            restore_best_weights=True\n        )\n    ]\n)","metadata":{"execution":{"iopub.status.busy":"2022-01-04T12:40:38.787873Z","iopub.execute_input":"2022-01-04T12:40:38.788314Z","iopub.status.idle":"2022-01-04T12:40:44.042084Z","shell.execute_reply.started":"2022-01-04T12:40:38.788279Z","shell.execute_reply":"2022-01-04T12:40:44.041229Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"y_pred = np.argmax(model.predict(X_test), axis=1)\n\ncm = confusion_matrix(y_test, y_pred, labels=list(LABEL_MAPPING.values()))\nclr = classification_report(y_test, y_pred, labels=list(LABEL_MAPPING.values()), target_names=list(LABEL_MAPPING.keys()))\n\nprint(\"Test Set Accuracy: {:.2f}%\".format(model.evaluate(X_test, y_test, verbose=0)[1] * 100))\n\nplt.figure(figsize=(8, 8))\nsns.heatmap(cm, annot=True, fmt='g', vmin=0, cmap='Blues', cbar=False)\nplt.xticks(ticks=[0.5, 1.5, 2.5, 3.5], labels=list(LABEL_MAPPING.keys()))\nplt.yticks(ticks=[0.5, 1.5, 2.5, 3.5], labels=list(LABEL_MAPPING.keys()))\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"Actual\")\nplt.title(\"Confusion Matrix\")\nplt.show()\n\nprint(\"Classification Report:\\n----------------------\\n\", clr)","metadata":{"execution":{"iopub.status.busy":"2022-01-04T12:40:44.043854Z","iopub.execute_input":"2022-01-04T12:40:44.044197Z","iopub.status.idle":"2022-01-04T12:40:45.357543Z","shell.execute_reply.started":"2022-01-04T12:40:44.044150Z","shell.execute_reply":"2022-01-04T12:40:45.356416Z"},"trusted":true},"execution_count":11,"outputs":[]}]}